{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T16:59:04.059679600Z",
     "start_time": "2024-02-23T16:59:03.598089600Z"
    }
   },
   "id": "f8668a2adcb9cc44",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data collection and data processing from the datalake"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "830f9bb7c4a858dc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Cargamos el dataset en un dataframe de pandas\n",
    "sonar_data = pd.read_csv('datalake/sonar_data.csv', header=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T17:04:46.033133200Z",
     "start_time": "2024-02-23T17:04:45.997136Z"
    }
   },
   "id": "938a3d0e47b9ebf7",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mostramos la estructura de nuestros datos."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "287a59372159681"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sonar_data.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53a617e7a3b0d5da",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Nos muestra el numero total de filas (208) y el numero total de columnas (61)\n",
    "sonar_data.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce13a4f711b72557",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Revela datos importantisimos sobre nuestro dataframe, como la desviacion estandar, los maximos, los minimos, los percentiles etc\n",
    "sonar_data.describe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e32ed06f1dc4d2f0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Queremos extraer el numero de minas y el numero de rocas definidas en nuestro dataset, para ello vamos a hacer un count de la columna con index 60.\n",
    "# M --> Mine\n",
    "\n",
    "# R --> R\n",
    "sonar_data[60].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cb4772f023a1044",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Vamos a hacer una agrupacion mediante el significado para poder ver los datos\n",
    "sonar_data.groupby(60).mean()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62879513f818f8bb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Vamos a eliminar el label, es decir, la ultima columna de nuestro dataset para preparar la ingesta y vamos a guardarlo en otra variable\n",
    "\n",
    "X = sonar_data.drop(columns=60, axis=1)\n",
    "Y = sonar_data[60]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T17:20:20.937981300Z",
     "start_time": "2024-02-23T17:20:20.923983800Z"
    }
   },
   "id": "3bb65c746b04e613",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(X)\n",
    "print(Y)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40af87e3e394a32b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Ahora vamos a separar nuestros datos en dos grupos, datos de entrenamiento y datos de prueba, esto es importante para que nuestro modelo sea entrenado con unos datos y probado con otros que no conozca, asi evitaremos \"falsos positivos\" o false fittings\n",
    "\n",
    "#Con la siguiente funcion vamos a splitear nuestro dataframe siguiendo los siguientes parametros\n",
    "# test_size=0.1 --> Aqui declaramos que queremos un 10% del dataset como datos reservados para pruebas.\n",
    "# stratify=Y --> Aqui vamos a indicarle que elemento vamos a usar para cortar nuestro dataset, en este caso, seran nuestros labels, M y R, esto provocara que se intenten distribuir de manera equitativa rocas y minas tanto en test data como en train data\n",
    "#random_state = Inicializa el valor del generador de numeros aleatorios en clave uno, es decir, si queremos reproducir la misma fase de entrenamiento, deberemos usar de nuevo la clave 1, si queremos usar otra, usaremos 2, 3, etc. Si querremos aleatorizar esta fase de manera no registrada, podemos inicializarlo con el valor None\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, stratify=Y, random_state=1)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7800f93405fc3c25"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
